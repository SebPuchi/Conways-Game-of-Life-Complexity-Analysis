# Topics
- Before even reading this list of topics I've made, please visit [the complexity zoo](https://complexityzoo.net/Complexity_Zoo) and take a look at some of what's here. Something catch your eye or interest you? There's your topic. You don't even need to read my list at that point. Want to be intrigued? Try looking up **ALL**. That's right, the nothing class - the class of all problems. Go ahead, see what it says. Everything here is interesting.
- The project ideas listed below are *by no means comprehensive*. It is merely meant to get you started. 
- For each project topic, I've included some background context attempting to 'sell you' on the idea based on what I know/remember. There are many topics of which I know nothing, and you are welcome to pick those topics - they just might not appear on this list! 
- Try not to make any inferences based on the length of the explanation. Some topics simply require more explanation than others. 
- Some of these are categories which include mult. Both are merely ideas. I am open to you going your own way with any topic. However, you should still read the topic descriptions to get an idea of what kind of work I'm expecting to see in your report. 
### More on NP
There's always more to say about **NP**. We're going to say quite a bit about **NP** in class. 
- **More completeness results**: We'll show that many problems are **NP** complete, but there's always more to show. I've heard that Super Mario Bros is **NP** complete. What's up with that? I think that for a project like ours, you'd need at least 4 more examples of **NP** completeness to have a full project, unless you're doing something particular creative or interesting with a particular one. For example, I think that many if not most roguelike video games such as the Binding of Isaac or Slay the Spire can be shown as **NP** complete if sufficiently formalized. This might even be publishable, and shouldn't be too difficult!
- **Coping with NP completeness**: We'll soon have shown that a variety of problems are **NP**-complete, and thus very likely intractably hard. But knowledge brings power. For coping with **NP**-completeness, there are plenty of options to explore. We have some very sophisticated $SAT$ solvers which perform well most of the time despite the worst case exponential runtime. We have approximation algorithms. We have simpler versions of most **NP**-complete problems, or polynomial time algorithms which give approximations. We won't have time to cover much of this, and so it would make for a good project topic. 
### Interactive Proof Systems and Game Theoretic Models
One way to conceive of **NP** is as an interaction between a prover and a verifier. The prover wants to prove to the verifier that $x \in L$ (whether it is or not - they are biased!). They are also a wizard - all powerful. The verifier, on the other hand, is human (if by human you mean a deterministic Turing machine), and also very busy - they don't have more than polynomial time to sift through an overly complicated proof. **NP** is what we get when we restrict the prover to a single interaction with the verifier (i.e. presenting them with a certificate). 

This points towards a way of generalizing the class **NP**: *Allow the verifier to send follow-up messages back to the prover*. It turns out that this only gets interesting when we also allow the verifier to be a *probabilistic Turing machine*, i.e. give them the option of conjuring up randomness with which to test the prover's claims. This leads us into the definition of three more important complexity classes: **AM**, **MA**, and **IP**. (This interactive protocol is called an **Arthur-Merlin game**, hence the acronyms. Arthur is the normal and skeptical human verifier, while Merlin is the all powerful but extremely biased wizard.)

I see two main directions which you could go with this project topic. Both would begin with you showing the basic definitions and relationships for **AM** and **MA** - e.g. where do they fit in our theory? After that, you could work towards either showing why these classes lead us to a particular problem - the *graph isomorphism problem*, likely being **NP-intermediate**, i.e. not in **P** but also not **NP-complete** - or you could move on to **IP** and work towards understanding (proving might be asking too much) that **IP = PSPACE**, and pointing out how this leads to a new way of understanding **PSPACE** and the problems inside of it. A third option would be to use this vantage point to prove an important fact: That either $\mathbf{BPP} = \mathbf{P}$ or $\mathbf{P} \neq \mathbf{NP}$. (See the randomized computation below for more on that.)

Additionally, there is another game theoretic body of research regarding provers and verifiers. *Probabilistically checkable proofs* is a whole body of research I know nothing about it. The central lynchpin is the so-called **PCP theorem**. I think that proving this theorem would be absolutely outside of the capabilities of any of you, but I think that the theory could still be explorable. It is my understanding that this could lead to a whole new way to approximate solutions to **NP**-complete problems, *in general*. 
### PSPACE
- **Alternating Turing machines** are a topic I know next to nothing about. There are various complexity classes to explore here. **AL**, **AP**, and so on. What are these? What is their relevance? How do they relate to the rest of complexity theory? In particular, it can be shown that **AP = PSPACE**. Working towards a proof of this would be a great project topic, I think.
- **PSPACE** completeness is as rich of a category of problems as **NP** completeness. Soon, we will do a deep dive into the world of **NP** complete problems. Doing the same but for **PSPACE** would be a great project. Your starting point would be the problem $QSAT$, or quantified satisfiability. Proving this is **PSPACE**-complete might be a challenge, but the results that follow - reductions from $QSAT$ to other problems, would be a great project topic. 
### Beyond PSPACE
$\mathbf{PSPACE}$, as we are beginning to see in our class, marks the big definite boundary point, beyond which nothing can be seen as efficiently computable exists. But that doesn't mean that there's nothing interesting out here. There is in fact plenty. 
- We've briefly touched on the class $\mathbf{EXP} = \bigcup TIME(2^{n^k})$. This is the beginning of a chain. Define $\mathbf{2EXP} = \bigcup TIME(2^{2^{n^k}})$, and similarly $\mathbf{3EXP}, \mathbf{4EXP}$, and son on. The union of all of these has a name: **ELEMENTARY**. Each of these has their own nondeterministic counterpart, and is nested inside of their own exponential analogs of **PSPACE**. What about elementary? I've heard there is a version of $SAT$, called $SUCCINT-SAT$, which is **NEXP** complete. Prove and explore that for a project?
- Is **ELEMENTARY** as big as it gets inside of **R**? Not even close. Exponentiation is only the third [hyperoperation](https://en.wikipedia.org/wiki/Hyperoperation), the first two being addition and multiplication. The fourth hyperoperation, *tetration*, commonly denoted $^ab$, would involve taking the number $b$ to the power of itself $a$ times. The time class $TIME(^n2)$, on it's own, contains *all* of $ELEMENTARY$. Prove that. (That's not at all a full project, but it would be a decent start.)
- We start to approach the limits of **R** when we do things like define the **Ackerman function** $A(n,k)$, which essentially takes two inputs, and performs the $n^{th}$ hyperoperation on $k$ with itself (if I remember correctly). There is a crucial distinction near the top of $R$, between the recursive (i.e. computable functions) and the so-called **primitive-recursive** functions. The Ackerman function in particular can be shown to be recursive but not primitive recursive - the first such function discovered. An thorough exploration of the Ackerman function would likely turn into more of a project about the recursive functions themselves, as their own model of computation (see below), but I have always had a question: Let $\mathbf{PRIM} \subseteq \mathbf{R}$ be the set of all primitively recursive languages. Is the union of all of the hyperoperation time classes equal to $\mathbf{PRIM}$? Does it contain $\mathbf{PRIM}$? I would love to see this question investigated, but it might be a longshot to ask any of you to do it as a project. Still, feel free to give it a shot.
### Inside* **L** 
**L** is the sacrificial lamb in our class, but that doesn't mean it has no theoretical value beyond acting as a baseline for reducibility. Far from it. I put the asterisk because most discussions of the classes contained inside of **L** eventually lead outside of it - with big implications. Here are some directions to take such a survey:
- **Circuit Complexity**: We will briefly touch on the potential for a circuit model of computation, and quickly see that it cannot be completely left unsupervised. However, there are circuit based complexity classes to define which have a lot of relevance. In particular, there are two hierarchical circuit classes: The **AC** circuit classes and the **NC** circuit classes. $\mathbf{AC}^0$ in particular is commonly seen as the *true* bottom of this theory. What can be said about these circuit classes? You are of course also free to veer outside of **L** if that's where your inquiries take you. How do these relate to our theory?
- ***Undirected* graph reachability** is actually a different problem from the regular graph reachability we've been focusing on. This problem's natural habitat isn't **NL** - but rather **RL** - randomized logarithmic space! What's going on here? Obviously, a definition of this class, a discussion of where it exists in relation to other classes, and a proof that the problem is **RL** complete, would be a minimal project plan.
### Parallel Computation
Papadimitrious has a whole chapter about this topic in his textbook, and I know next to nothing about it. Because of this, I don't have much guidance to give on the topic. He defines a class called **RNC**. What is this? How does it relate to the classes we've seen in our class? What kinds of parallel models of computation are there? How does the result we obtained in class about $k$-string Turing machines relate to this theory? How much can parallelism actually change about the landscape of complexity theory?
### Randomized computation
- Problems in **BPP**, **ZPP**, and **RP**. We'll define these three complexity classes during class, but we won't have time to go through many of the problems found inside of these classes in much detail. A survey of these problems would be equivalent to a survey of where randomness serves to provide definite speedup to practical modern computation. 
- **Derandomization**: The question of whether or not $\mathbf{BPP} = \mathbf{P}$ is closely related to the question whether or not $\mathbf{P} \neq \mathbf{NP}$: it can be shown that at least one of these has to be true (e.g. it can be shown that $(\mathbf{BPP} = \mathbf{P}) \vee (\mathbf{P} \neq \mathbf{NP})$). This means that proving $\mathbf{BPP} \neq \mathbf{P}$ would also prove that $\mathbf{P} \neq \mathbf{NP}$. Proving these is it's own project topic, and can be done from the vantage point of interactive proof systems (see above). However, this is likely not a worthwhile avenue to proving that $\mathbf{P} \neq \mathbf{NP}$, as it is widely believed that $\mathbf{BPP} = \mathbf{P}$. It is my understanding that there have been some major gains in actually proving this definitively in recent years. The umbrella topic for looking into these gains is the subject of *derandomization* - taking a probabilistic solution to a problem and sucking the randomness out of it in order to produce a deterministic computation which accomplishes the same thing. I've never looked into this area of research closely. It is likely very challenging, but also sounds mighty interesting. 
### Quantum Computing (Off limits if you have not taken linear algebra! Even then, with approval only!)
I'm only putting this here because I'm sure plenty of you are thinking about this one. I'm sorry, but unless you are really, *really* sharp with your linear algebra, you just aren't going to get anywhere with this theory in half a semester. That said, **BQP**, short for **bounded error quantum polynomial time**, is obviously a very important complexity class in this theory. **BQP** can be understood as two different but equivalent models of computation. There is the *quantum circuit* model, which is the practical one that nearly everyone works when developing quantum algorithms, but which is hard to connect to a broader complexity theory with, and then there is the *quantum Turing machine* model, which extends our definition of the Turing machine. Either of these would be separate directions to go with this topic. If you were going in the former direction, I would expect you to show me... something. Either an overview of how the model works, or a problem being solved within it. I'd also appreciate you making some connections to **P** and **NP** at least, but that's probably all you'd be able to do within the circuit model. If you were going with the latter, I'd expect to see details of the definition and some connections with the theory as we laid it out in class. For example, it can be shown that $\mathbf{BQP} \subseteq \mathbf{PSPACE}$ (in fact, $\mathbf{BQP} \subseteq \mathbf{PP}$, an outer probabilistic complexity class which we will probably get around to defining later).

If you want to do this topic, you need to come to my office and convince me that you have the grit and prior knowledge to actually go in and learn something definite. Otherwise, you won't be able to take the rigorous theoretical lens to the theory that I am expecting from this project. 
### Oracle Relativization
Let $O$ be a decision problem. A **Turing machine with oracle O**, denoted $M^O$, is a Turing machine equipped with a special superpower: *it can, at any time, decide instances of $O$ in one step*. Oracles have a variety of uses in complexity theory. Firstly, they allow us to classify hierarchies of difficulty between **NP** and **PSPACE**, which is something we will touch on towards the end of the class. (For example, there are certain problems which, while not strictly *reducible* to problems in **NP**, can be solved efficiently up to needing the answer to a polynomial number of **NP** problems. Oracles are a natural way to formally define these kinds of problems.) Perhaps most importantly, they exist as a formal way to speculate about complexity theory in the absense of hard results. For example, consider a problem $L$. Is it in **P**? Who knows. But what if we were in a world in which it was? What would change about complexity theory in a world where $L$ *was* efficiently computable?

There are a ton of interesting results here. For example, there are oracles separating **P** from **NP** and oracles equating them. One can show that if you were to draw a problem out of a hat at random, then the probability that **P** is not equal to **NP** if that problem turned out to be efficiently computable is 100%. This was taken as extremely strong evidence that **P** was not equal to **NP**, until, amazingly, it was shown that **IP = PSPACE**. You don't need to know what **IP** is (although that's another project topic!) - just that it was also shown prior to this result that in the same sense, **IP** was not equal to **PSPACE** with 100% probability! 

My own dissertation research, incidentally, is all about oracle relativization. I wouldn't exactly say that this stuff is near and dear to my heart (in fact, I'd rather not do further research on it), but I would certainly be able to help a good amount with this topic, if you chose it. Your task would be to demonstrate several of these results. *At the very least*, I would expect you to build the oracles separating **P** from **NP** and equating them, and prove those results. I would consider that an extremely minimal research paper. Hopefully, you would have a couple other results to show beyond this. There are plenty!
### Other Models of Computation
We talked early on in the class about the notion of Turing completeness. For an investigation of complexity theory, it is hard to argue with picking out and focusing on the Turing machine model. However, that doesn't mean that there aren't other theoretical models which have value in studying. One possible direction for a project is to do exactly this. 
##### The Recursive Functions 
Perhaps the most important purely theoretical 'model' of computation aside from Turing machines, which is ironic because these are only arguably a model of computation. Really, they are an inductively defined collection of functions $f:\mathbb{N} \to \mathbb{N}$. However, these functions have a one to one correspondence with the set of all Turing computable functions - up to a standardized encodings of strings to numbers. Moreover, the recursive function 'model' is the natural vantage point from which to witness an important distinction in computer science - that between the *primitive recursive* functions, and the *fully* (or *total*) recursive functions - e.g. a class $\mathbf{PRIM} \subseteq \mathbf{R} \subseteq \mathbf{RE}$ (where in the world of recursive functions, $\mathbf{RE}$ would correspond to the set of *partial recursive functions*). The distinction between $\mathbf{PRIM}$ and $\mathbf{R}$ amounts to many things, but first and foremost it ends up amounting to the question: are `for` loops the same as `while` loops? Do we really need both? Is one type of loop more powerful than the other? I have a couple projects in mind which you could choose to do involving these.
	- Idea 1: Prove the equivalence between these functions and the set of Turing computable functions. Turing himself did this in his original paper defining Turing machines, and it is a beautiful argument. You would be doing this from the ground up - starting from the definition, you would 'build' progressively more complicated functions, with the goal of showing that the function $\pi(n)$ which returns the $n^{th}$ prime number is primitive recursive. After that, use this function to define a primitive recursive encoding scheme for strings. Finally, you'll be equipped to show that for any Turing machine, there is a partial recursive function which, given the number encoding of a string input to that machine, returns the number encoding the output of the machine on that input (or returning $\nearrow$ if the machine fails to halt). 
	- Idea 2: What is the difference between $\mathbf{PRIM}$ and $\mathbf{R}$? The answer has a name. Ackerman. Define the Ackerman function, attempt to understand it, and show that the Ackerman function is total recursive but *not* primitive recursive. 
These two ideas are not completely independent, and the starting point (building up successively more complicated recursive functions) is the same regardless of which of these topics you want to pursue. Both is also an option. 
##### The Lambda Calculus
Historically, the original 'big three' models of computation were the Turing model, the recursive function, and Church's so-called *lambda calculus*. This one is noteworthy in that it actually has direct relevance to practical computer science, depending on who you are. The lambda calculus is the theoretical basis for the *functional programming* paradigm, enforced by languages like Haskell and scheme. I'll be honest though, I know very little about this model! I therefore don't have the same guidance to give for an investigation of this model. I'd like to at least see a demonstration of the equivalence between this model and the Turing machine model. Past that is up to you. 
##### More?
Have a different model of computation in mind you want to explore? Run it by me. I'm sure we can work something out. 
### Automata Theory and Formal Linguistics
In our class, we jumped straight into the Turing model. A Turing machine is a *state machine*, or *automata* - a predictable device that solves a problem by iterating based on rules defined by the machine's current state. However, Turing machines reside near the top of a hierarchy of progressively more and more complicated and powerful automata called the *Chomsky Hierarchy*. The Chomsky hierarchy is defined not by the machines themselves, but by the languages which are decided by such machines. From bottom to top, this hierarchy is: the *regular languages* (corresponding to regular expressions), the *context-free* languages, the *recursive* languages ($\mathbf{R}$), the *recursively enumerable* languages ($\mathbf{RE}$), and finally the *context-sensitive* languages. Each class of languages corresponds to a class of automata *as well as* a class of formal grammars from which languages can be defined. 

Just like with the recursive functions, there are many directions in which you could take a research project over automata theory. You could start at the bottom and briefly survey each level, or you could park at a particular level and investigate it in detail, or a bit of both. What is important is that whatever you choose to do, your project includes mathematical proofs and develops a body of results. You can go in whatever direction your nose (or the papers/textbooks you are reading) take you. 
### Uncomputability and Beyond, Logic Connections, etcetera
- **Uncomputability**: We saw that the Halting problem was uncomputable. One simple project would be to go further and show at least three more examples of uncomputable problems. There's a lot of fun stuff here - Busy beaver games, domino puzzles, and more! 
- **The arithmetic hierarchy**: Going off of uncomputability, most problems are demonstrated to be uncomputable by proving that the halting problem reduces to them. This would make them $\mathbf{RE}$-hard. However some uncomputable problems are harder than others. In fact, the halting problem, and other problems in $\mathbf{RE}$, belong to the *easiest* tier of uncomputability. Late in the class, we will likely define the *polynomial hierarchy*, of which $\mathbf{NP}$ is at the first tier. An anologous hierarchy, called the *arithmetic hierarchy*, exists as the original inspiration for this hierarchy we'll be discussing it in class. If you're interested in connections to logic, and in particular Gödel's theorems, this project topic is for you! In fact, let me outline that process to you:
	- First, define the arithmetic hierarchy in terms of Turing machines and decidable problems. 
	- Fix a first-order model in the language of number theory. Call it $\mathbb{N}$. If you're feeling particularly Platonic (ew, but I get it), think of it as the 'true' model that you've been working with since you were a child. 
	- Define the arithmetic hierarchy again in terms of definable relations in the language of number theory. Show that it is equivalent to the first definition you gave, up to a standard encoding. 
	- Define two(ish) decision problems: 
		- $TRUTH$: Given a sentence in the language of number theory $\phi$, does our fixed model $\mathbb{N}$ satisfy $\phi$? I.e., does $\mathbb{N} \models \phi$? 
		- $PROOF_{\Gamma}$: Here, $\Gamma$ is a recursively enumerable set of axioms in the language of number theory. Given a sentence in the language of number number theory $\phi$, is $\phi$ proveable from the axiom system $\Gamma$? I.e., does $\Gamma \vdash \phi$? 
	- Show that $PROOF_{\Gamma} \in \mathbf{RE}$ for any recursively enumerable set of axioms $\Gamma$. 
	- Show that if $TRUTH \in \mathbf{RE}$, then $TRUTH \in \mathbf{R}$. (Hint: every sentence is either going to be true or false for any model.)
	- Show that if $TRUTH \in \mathbf{R}$, then the arithmetic hierarchy collapses down to $\Delta_1 = \mathbf{R}$. In particular, $\Sigma_1 = \mathbf{RE} \subseteq \mathbf{R}$. 
	- However, we know that $\mathbf{RE} \nsubseteq \mathbf{R}$, because the Halting problem is uncomputable.
	- Thus, we have to conclude that $TRUTH \notin \mathbf{R}$, and therefore contrapositively is not in $\mathbf{RE}$ either. 
	- Since $PROOF_{\Gamma} \in \mathbf{RE}$ for any reasonable axiom system $\Gamma$, we must conclude that there does not exist an axiom system $\Gamma$ which fully axiomatizes $\mathbb{N}$, i.e. no $\Gamma$ such that $PROOF_{\Gamma} = TRUTH$. This is Gödel's second incompleteness theorem.  
	- Follow up question: Where *is* $TRUTH$ then? Can it exist anywhere in the arithmetic hierarchy? 
	- Second follow up question. I pretty much gave you the outline for the second incompleteness theorem from a computability standpoint. What about the first one?
### Average case complexity theory?
There is a chapter in the Arora and Barak book which attempts to define and explore an average case complexity theory (as opposed to our implicitly *worst-case* complexity theory.) I know less than nothing about this theory, but exploring it could be a great topic!
### Cryptography
We'll briefly touch on the cryptography connection in our class, but there will be a lot left unsaid. **UP** is the relevant class here - a weird guy nested in betwneen **P** and **NP**. However, there's a lot more to say. You could do a report on zero knowledge protocols, one-way functions, and a bunch more. I will provide one important and more structured project topic here: 
- The problem $PRIMES$ - Given an integer $n$, is it prime? - is the dual of the $FACTORING$ problem we're familiar with. As such, where $FACTORING \in \mathbf{NP}$, $PRIMES \in \mathbf{coNP}$. However, surprisingly, it can be shown that $PRIMES \in \mathbf{NP}$ as well. This makes the $PRIMES$ problem noteworthy as a problem which exists in the *intersection* of $\mathbf{NP}$ and $\mathbf{coNP}$, but still not in $\mathbf{P}$. Or at least... it was, until it was shown to be in $\mathbf{P}$ as well! As a project, you could dive into some number theory in order to show that $PRIMES \in \mathbf{NP}$. As a stretch goal, you could also look into the proof that $PRIMES \in \mathbf{P}$. 
